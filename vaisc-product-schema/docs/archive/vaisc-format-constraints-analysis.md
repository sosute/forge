# VAISC データインポート形式制約の調査結果

## ⚠️ 重要な発見

**Google Cloud Vertex AI Search for Commerce (VAISC) は、商品カタログのインポートにCSV形式をサポートしていません。**

## 1. VAISCでサポートされているデータインポート形式

### 1.1 サポートされている形式
| 形式 | 説明 | 推奨用途 |
|------|------|----------|
| **JSON** | 主要サポート形式 | 小〜中規模インポート |
| **BigQuery** | 推奨形式 | 大規模データインポート |
| **Inline Request** | API直接投入 | 少量データ（<100アイテム） |
| **Google Merchant Center** | 既存Googleアカウント連携 | 新規ユーザーは非推奨 |

### 1.2 ❌ サポートされていない形式
- **CSV形式**: 商品カタログのインポートではサポート外
- **XML形式**: 公式サポートなし
- **Excel形式**: 公式サポートなし

## 2. 推奨されるデータインポート方法

### 2.1 🎯 推奨: BigQuery経由のインポート
```
既存DB → BigQuery → VAISC
```

**利点:**
- 大規模データに対応
- スキーマ検証自動実行
- 段階的データ変換可能
- Google Cloud 内でのシームレス連携

**要件:**
- BigQueryにVertex AI Search for commerce専用スキーマでテーブル作成
- UTF-8エンコーディング必須
- 同一リージョンでの配置

### 2.2 代替案: JSON形式でのCloud Storageインポート
```
既存DB → JSON変換 → Cloud Storage → VAISC
```

**制約:**
- 1ファイル最大2GB
- 同時インポート最大100ファイル
- JSONは1行1商品形式（JSONL）
- JSON内での改行文字禁止

## 3. VAISC Product Schema 必須仕様

### 3.1 必須フィールド（Required）
| フィールド名 | データ型 | 説明 | 制約 |
|-------------|----------|------|------|
| `id` | STRING | 商品ID | 一意、UTF-8、カタログ内でユニーク |
| `title` | STRING | 商品名 | UTF-8 |
| `categories` | STRING[] | カテゴリ（配列） | 少なくとも1つ以上 |

### 3.2 推奨フィールド（Recommended）
| フィールド名 | データ型 | 説明 |
|-------------|----------|------|
| `description` | STRING | 商品説明 |
| `priceInfo` | RECORD | 価格情報 |
| `images` | RECORD[] | 画像情報 |
| `attributes` | RECORD[] | カスタム属性 |

### 3.3 カスタム属性（attributes）の定義ルール
```json
{
  "attributes": {
    "カスタムキー名": {
      "text": ["テキスト値1", "テキスト値2"],
      "numbers": [数値1, 数値2]
    }
  }
}
```

**制約:**
- キー名: UTF-8文字列
- 値: textまたはnumbersのみ
- 配列形式での複数値サポート

## 4. データ形式制約詳細

### 4.1 文字エンコーディング
- **必須**: UTF-8
- **禁止**: Shift_JIS、EUC-JP等の他エンコーディング

### 4.2 データサイズ制限
| 制限項目 | 制限値 |
|----------|--------|
| 1ファイルサイズ | 最大2GB |
| 同時インポートファイル数 | 最大100 |
| Inline Request商品数 | 最大5,000（推奨100） |
| 1商品あたりの属性数 | 制限なし（パフォーマンス要考慮） |

### 4.3 日付形式
- **必須形式**: RFC 3339形式
- **例**: `2025-09-23T10:00:00Z`
- **禁止**: YYYY-MM-DD等の簡易形式

### 4.4 配列データ
- **JSON**: サポート
- **BigQuery**: サポート
- **CSV**: サポート外（配列使用不可）

## 5. プロジェクトへの影響分析

### 5.1 🚨 現在のCSVフォーマット戦略の見直しが必要

**問題:**
- 作成したCSVフォーマット仕様はVAISCで直接利用不可
- CSV → VAISC の直接インポートパスが存在しない

**対応策:**
1. **BigQuery経由アプローチ**: CSV → BigQuery → VAISC
2. **JSON変換アプローチ**: CSV → JSON変換 → Cloud Storage → VAISC

### 5.2 推奨実装アプローチ

#### アプローチ1: BigQuery経由（推奨）
```
既存DB → CSVエクスポート → BigQuery Import → VAISC Import
```

**利点:**
- 既存のCSVフォーマット仕様活用可能
- 大規模データ対応
- データ変換処理をBigQuery SQLで実装

**実装手順:**
1. VAISC対応BigQueryテーブル作成
2. CSVデータのBigQuery投入
3. BigQueryでデータ変換（カスタム属性JSON化等）
4. BigQueryからVAISCへインポート

#### アプローチ2: JSON変換プログラム開発
```
既存DB → CSVエクスポート → JSON変換プログラム → Cloud Storage → VAISC
```

**利点:**
- シンプルなデータフロー
- 小〜中規模データに適している

**実装要件:**
- CSVからJSONL形式への変換プログラム
- カスタム属性のJSON構造化処理
- エラーハンドリング機能

## 6. 修正された実装計画

### 6.1 フェーズ1: データ変換システム構築
- **目標**: CSVからVAISC対応形式への変換
- **方法**: BigQuery経由またはJSON変換プログラム
- **期間**: 既存フェーズに追加作業として組み込み

### 6.2 フェーズ2: VAISC統合
- **目標**: 変換されたデータでのVAISC動作確認
- **方法**: 少量データでの検証テスト
- **成果物**: 動作確認済みデータインポートプロセス

### 6.3 フェーズ3: 本格運用
- **目標**: 全商品データでの本格運用
- **方法**: 段階的データ移行
- **要件**: 定期更新プロセスの確立

## 7. 既存作業の活用方法

### 7.1 ✅ 継続利用可能な成果物
- **CSVフィールド定義**: BigQueryテーブル設計の基礎として活用
- **DB項目マッピング**: データ変換ロジックの仕様として活用
- **API機能要件**: VAISCカスタム属性設計の基礎として活用

### 7.2 🔄 修正が必要な成果物
- **CSVフォーマット仕様**: BigQuery Schema または JSON Schema に変換
- **インポート手順**: 直接CSV投入 → 変換プロセス経由に変更

## 8. 次のアクションアイテム

### 8.1 必須タスク
1. **BigQuery Schema設計**: CSVフィールドをBigQueryテーブル構造に変換
2. **データ変換仕様策定**: CSV → BigQuery/JSON の変換ルール定義
3. **実装方式選定**: BigQuery経由 vs JSON変換プログラムの技術選定

### 8.2 検証タスク
1. **サンプルデータテスト**: 少量データでのエンドツーエンド動作確認
2. **パフォーマンステスト**: 大量データでの処理時間・リソース使用量確認
3. **エラー処理テスト**: 異常データでのエラーハンドリング確認

---

**⚠️ 重要な結論:**
VAISCはCSVの直接インポートをサポートしていないため、データ変換プロセスが必須です。しかし、これまでの分析結果は変換仕様の設計に活用できるため、作業は無駄になりません。